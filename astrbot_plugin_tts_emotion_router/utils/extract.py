# -*- coding: utf-8 -*-
from __future__ import annotations

import re
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass


@dataclass
class ExtractedContent:
    """æå–çš„ä»£ç æˆ–é“¾æ¥å†…å®¹"""
    type: str  # "code" æˆ– "link"
    content: str
    line_start: Optional[int] = None
    line_end: Optional[int] = None
    language: Optional[str] = None


class CodeAndLinkExtractor:
    """æå–æ–‡æœ¬ä¸­çš„ä»£ç å—å’Œé“¾æ¥"""
    
    def __init__(self):
        # ä»£ç å—æ­£åˆ™ - åŒ¹é… ```language\n...\n``` æˆ– `inline code`
        self.code_block_re = re.compile(
            r'```([a-zA-Z0-9_+-]*)\n(.*?)\n```',
            re.DOTALL
        )
        self.inline_code_re = re.compile(
            r'`([^`\n]+)`'
        )
        
        # é“¾æ¥æ­£åˆ™
        self.url_re = re.compile(
            r'https?://[^\s<>"{}|\\^`\[\]]+',
            re.IGNORECASE
        )
        self.www_re = re.compile(
            r'www\.[^\s<>"{}|\\^`\[\]]+\.[^\s<>"{}|\\^`\[\]]+',
            re.IGNORECASE
        )
        # ç½‘å€æ­£åˆ™ï¼ˆåŒ¹é… xxx.xxx æ ¼å¼ï¼‰
        self.website_re = re.compile(
            r'[a-zA-Z0-9][a-zA-Z0-9-]{1,61}[a-zA-Z0-9]\.[a-zA-Z]{2,}(?:\.[a-zA-Z]{2,})?',
            re.IGNORECASE
        )
        
        # å¸¸è§çš„æŠ€æœ¯æœ¯è¯­å’Œæ¨¡å‹å - è¿™äº›ä¸åº”è¯¥è¢«è§†ä¸ºä»£ç 
        self.tech_terms = {
            # AIæ¨¡å‹
            'gpt', 'gpt-3.5', 'gpt-4', 'gpt-4-turbo', 'chatgpt',
            'claude', 'claude-2', 'claude-3', 'gemini', 'llama',
            'mistral', 'mixtral', 'qwen', 'baichuan', 'yi',
            'deepseek', 'codegeex', 'pangu', 'xunfei',
            # å¸¸è§æŠ€æœ¯åè¯
            'api', 'rest', 'json', 'xml', 'html', 'css', 'js',
            'python', 'java', 'javascript', 'typescript', 'c++',
            'tensorflow', 'pytorch', 'torch', 'numpy', 'pandas',
            'docker', 'kubernetes', 'k8s', 'linux', 'windows',
            'macos', 'ios', 'android', 'web', 'frontend', 'backend',
            # ç‰ˆæœ¬å·
            r'v?\d+\.\d+(\.\d+)?',
            r'\d+\.\d+(\.\d+)?',
        }
        
        # ç¼–è¯‘æŠ€æœ¯æœ¯è¯­æ­£åˆ™
        self.tech_terms_re = re.compile(
            r'\b(' + '|'.join(re.escape(term) for term in self.tech_terms) + r')\b',
            re.IGNORECASE
        )
    
    def extract_code_blocks(self, text: str) -> List[ExtractedContent]:
        """æå–ä»£ç å—"""
        results = []
        
        # æå–å¤šè¡Œä»£ç å—
        for match in self.code_block_re.finditer(text):
            language = match.group(1).strip() or None
            code_content = match.group(2)
            
            # å¦‚æœä»£ç å†…å®¹çœ‹èµ·æ¥åƒæ˜¯æŠ€æœ¯æœ¯è¯­è€Œéå®é™…ä»£ç ï¼Œè·³è¿‡
            if self._is_likely_tech_term(code_content):
                continue
                
            results.append(ExtractedContent(
                type="code",
                content=code_content,
                language=language
            ))
        
        # æå–è¡Œå†…ä»£ç 
        for match in self.inline_code_re.finditer(text):
            code_content = match.group(1)
            
            # å¦‚æœæ˜¯å•ä¸ªæŠ€æœ¯æœ¯è¯­ï¼Œè·³è¿‡
            if self._is_likely_tech_term(code_content):
                continue
                
            # å¦‚æœæ˜¯ç‰ˆæœ¬å·æˆ–ç®€å•çš„æŠ€æœ¯å¼•ç”¨ï¼Œè·³è¿‡
            if self._is_simple_tech_reference(code_content):
                continue
                
            results.append(ExtractedContent(
                type="code",
                content=code_content
            ))
        
        return results
    
    def extract_links(self, text: str) -> List[ExtractedContent]:
        """æå–é“¾æ¥"""
        results = []
        
        # æå–å®Œæ•´URL
        for match in self.url_re.finditer(text):
            results.append(ExtractedContent(
                type="link",
                content=match.group(0)
            ))
        
        # æå–wwwå¼€å¤´çš„é“¾æ¥
        for match in self.www_re.finditer(text):
            results.append(ExtractedContent(
                type="link",
                content=match.group(0)
            ))
        
        # æå–ç½‘å€æ ¼å¼ï¼ˆå¦‚ github.comï¼‰
        for match in self.website_re.finditer(text):
            # æ’é™¤ä¸€äº›å¸¸è§çš„æŠ€æœ¯æœ¯è¯­
            domain = match.group(0).lower()
            if domain not in ['api.com', 'example.com', 'test.com'] and not domain.endswith('.js'):
                results.append(ExtractedContent(
                    type="link",
                    content=match.group(0)
                ))
        
        return results
    
    def extract_all(self, text: str) -> List[ExtractedContent]:
        """æå–æ‰€æœ‰ä»£ç å’Œé“¾æ¥"""
        code_blocks = self.extract_code_blocks(text)
        links = self.extract_links(text)
        return code_blocks + links
    
    def clean_text_for_tts(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤ä»£ç å—å’Œé“¾æ¥ï¼Œå‡†å¤‡ç”¨äºTTS"""
        # ç§»é™¤å¤šè¡Œä»£ç å—
        text = self.code_block_re.sub('', text)
        
        # ç§»é™¤è¡Œå†…ä»£ç ï¼ˆä¿ç•™æŠ€æœ¯æœ¯è¯­ï¼‰
        text = self.inline_code_re.sub(
            lambda m: m.group(1) if self._is_likely_tech_term(m.group(1)) else '',
            text
        )
        
        # ç§»é™¤é“¾æ¥
        text = self.url_re.sub('', text)
        text = self.www_re.sub('', text)
        text = self.website_re.sub('', text)
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def format_references(self, extracts: List[ExtractedContent]) -> str:
        """å°†æå–çš„å†…å®¹æ ¼å¼åŒ–ä¸ºå‚è€ƒæ–‡çŒ®"""
        if not extracts:
            return ""
        
        references = []
        code_count = 0
        link_count = 0
        
        for extract in extracts:
            if extract.type == "code":
                code_count += 1
                if extract.language:
                    references.append(f"[ä»£ç {code_count}] {extract.language}ä»£ç ç‰‡æ®µ")
                else:
                    references.append(f"[ä»£ç {code_count}] ä»£ç ç‰‡æ®µ")
                # æ·»åŠ ä»£ç å†…å®¹ï¼ˆæˆªæ–­è¿‡é•¿çš„ä»£ç ï¼‰
                code_preview = extract.content.replace('\n', ' ')
                if len(code_preview) > 100:
                    code_preview = code_preview[:97] + "..."
                references[-1] += f": {code_preview}"
                    
            elif extract.type == "link":
                link_count += 1
                references.append(f"[é“¾æ¥{link_count}] {extract.content}")
        
        if references:
            return "\n\nğŸ“š å‚è€ƒæ–‡çŒ®å’Œä»£ç ç‰‡æ®µï¼š\n" + "\n".join(references)
        return ""
    
    def _is_likely_tech_term(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæŠ€æœ¯æœ¯è¯­è€Œéå®é™…ä»£ç """
        text = text.strip().lower()
        
        # å¦‚æœæ˜¯å•ä¸ªè¯ä¸”åŒ¹é…æŠ€æœ¯æœ¯è¯­
        if ' ' not in text and self.tech_terms_re.fullmatch(text):
            return True
            
        # å¦‚æœæ˜¯ç®€å•çš„ç‰ˆæœ¬å·æˆ–æ¨¡å‹å
        if re.match(r'^[a-zA-Z-]+/\d+\.\d+$', text):  # å¦‚ openai/3.5
            return True
            
        return False
    
    def _is_simple_tech_reference(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç®€å•çš„æŠ€æœ¯å¼•ç”¨"""
        text = text.strip()
        
        # å¦‚æœåªæ˜¯æ¨¡å‹åæˆ–ç‰ˆæœ¬å·
        if re.match(r'^(gpt|claude|gemini|llama|qwen|yi|deepseek)-?\d*\.?\d*$', text, re.I):
            return True
            
        # å¦‚æœåªæ˜¯ç®€å•çš„ç‰ˆæœ¬å·
        if re.match(r'^v?\d+\.\d+(\.\d+)?$', text):
            return True
            
        return False


# å…¨å±€å®ä¾‹
extractor = CodeAndLinkExtractor()